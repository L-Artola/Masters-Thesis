---
title: "FDIC API test"
output: html_document
---

```{r setup, include=FALSE}
rm(list=ls())

# Stepwise logistic regression
library(MASS)
library(caret)
library(glmnet)
library(tidymodels)
library(recipes)
library(httr)
library(dplyr)
library(ggrepel)
library(tidyverse)
library (ggplot2)
library(themis)
# test skewness
library(moments)

#bocox transformation
library(EnvStats)
library(corrplot)

#correlation table
library(reshape2)

library(doParallel)

#PCA
library(factoextra)
library(pcaPP)
```


# Creating a list of bank faliure identifers
```{r}

bank_failures <- read.csv("Bank Failures Oct-2000 - 2020.csv")

#Removing after 2013
#bank_failures_1 <-  bank_failures[!grepl(c("19|20|17|16|15|14"), bank_failures$Closing.Date.),] 
bank_failures_1 <-  bank_failures[!grepl(c("19|20|17|16|15|000|01|02|03|04|05"), bank_failures$Closing.Date.),]
head(bank_failures_1)

# Failed Bank Identifiers
bank_failures_2 <- bank_failures_1 %>%
        select(Cert.)


bank_failures_1
head(bank_failures_1)

#06|07|08
```



# Pulling in Quaterly Ratios, adding in quater Identifers, removing irrelevant predictors
# Cert is the Personal Identifier of each Bank
# Cleaned data from 2000-2013. Test case
#Joining Quaterly data together
```{r}
#Q1 2000
Q12000 <- read.csv("2000Q1.csv")
table(Q12000$bkclass)

Q12000$date <- "1Q2000"
Q12000_1 <- Q12000 %>%
        select(!c(docket:idntigr))


#Q2 2000
Q22000 <- read.csv("2000Q2.csv")
Q22000$date <- "2Q2000"
Q22000_1 <- Q22000 %>%
        select(!c(docket:idntigr))



# Q3 2000
Q32000 <- read.csv("2000Q3.csv")
Q32000$date <- "3Q2000"
Q32000_1 <- Q32000 %>%
        select(!c(docket:idntigr))

#Q4 2000
Q42000 <- read.csv("2000Q4.csv")
Q42000$date <- "4Q2000"
Q42000_1 <- Q42000 %>%
        select(!c(docket:idntigr))



#Q1 2001
Q12001 <- read.csv("2001Q1.csv")

Q12001$date <- "1Q2001"
Q12001_1 <- Q12001 %>%
        select(!c(docket:idntigr))


#Q2 2001
Q22001 <- read.csv("2001Q2.csv")

Q22001$date <- "2Q2001"
Q22001_1 <- Q22001 %>%
        select(!c(docket:idntigr))


#Q3 2001
Q32001 <- read.csv("2001Q3.csv")

Q32001$date <- "3Q2001"
Q32001_1 <- Q32001 %>%
        select(!c(docket:idntigr))


#Q4 2001
Q42001 <- read.csv("2001Q4.csv")

Q42001$date <- "4Q2001"
Q42001_1 <- Q42001 %>%
        select(!c(docket:idntigr))


#Q1 2002
Q12002 <- read.csv("2002Q1.csv")

Q12002$date <- "1Q2002"
Q12002_1 <- Q12002 %>%
        select(!c(docket:idntigr))


#Q2 2002
Q22002 <- read.csv("2002Q2.csv")

Q22002$date <- "2Q2002"
Q22002_1 <- Q22002 %>%
        select(!c(docket:idntigr))

#Q3 2002
Q32002 <- read.csv("2002Q3.csv")

Q32002$date <- "3Q2002"
Q32002_1 <- Q32002 %>%
        select(!c(docket:idntigr))


#Q4 2002
Q42002 <- read.csv("2002Q4.csv")

Q42002$date <- "4Q2002"
Q42002_1 <- Q42002 %>%
        select(!c(docket:idntigr))


#Q1 2003
Q12003 <- read.csv("2003Q1.csv")

Q12003$date <- "1Q2003"
Q12003_1 <- Q12003 %>%
        select(!c(docket:idntigr))


#Q2 2003
Q22003 <- read.csv("2003Q2.csv")

Q22003$date <- "2Q2003"
Q22003_1 <- Q22003 %>%
        select(!c(docket:idntigr))


#Q3 2003
Q32003 <- read.csv("2003Q3.csv")

Q32003$date <- "3Q2003"
Q32003_1 <- Q32003 %>%
        select(!c(docket:idntigr))


#Q4 2003
Q42003 <- read.csv("2003Q4.csv")

Q42003$date <- "4Q2003"
Q42003_1 <- Q42003 %>%
        select(!c(docket:idntigr))


#Q1 2004
Q12004 <- read.csv("2004Q1.csv")

Q12004$date <- "1Q2004"
Q12004_1 <- Q12004 %>%
        select(!c(docket:idntigr))


#Q2 2004
Q22004 <- read.csv("2004Q2.csv")

Q22004$date <- "2Q2004"
Q22004_1 <- Q22004 %>%
        select(!c(docket:idntigr))

#Q3 2004
Q32004 <- read.csv("2004Q3.csv")

Q32004$date <- "3Q2004"
Q32004_1 <- Q32004 %>%
        select(!c(docket:idntigr))

#Q4 2004
Q42004 <- read.csv("2004Q4.csv")

Q42004$date <- "4Q2004"
Q42004_1 <- Q42004 %>%
        select(!c(docket:idntigr))


#Q1 2005
Q12005 <- read.csv("2005Q1.csv")

Q12005$date <- "1Q2005"
Q12005_1 <- Q12005 %>%
        select(!c(docket:idntigr))

#Q2 2005
Q22005 <- read.csv("2005Q2.csv")

Q22005$date <- "2Q2005"
Q22005_1 <- Q22005 %>%
        select(!c(docket:idntigr))


#Q3 2005
Q32005 <- read.csv("2005Q3.csv")

Q32005$date <- "3Q2005"
Q32005_1 <- Q32005 %>%
        select(!c(docket:idntigr))


#Q4 2005
Q42005 <- read.csv("2005Q4.csv")

Q42005$date <- "4Q2005"
Q42005_1 <- Q42005 %>%
        select(!c(docket:idntigr))


#Q1 2006
Q12006 <- read.csv("2006Q1.csv")

Q12006$date <- "1Q2006"
Q12006_1 <- Q12006 %>%
        select(!c(docket:idntigr))


#Q2 2006
Q22006 <- read.csv("2006Q2.csv")

Q22006$date <- "2Q2006"
Q22006_1 <- Q22006 %>%
        select(!c(docket:idntigr))


#Q3 2006
Q32006 <- read.csv("2006Q3.csv")

Q32006$date <- "3Q2006"
Q32006_1 <- Q32006 %>%
        select(!c(docket:idntigr))
#Q4 2006
Q42006 <- read.csv("2006Q4.csv")

Q42006$date <- "4Q2006"
Q42006_1 <- Q42006 %>%
        select(!c(docket:idntigr))


#Q1 2007
Q12007 <- read.csv("2007Q1.csv")

Q12007$date <- "1Q2007"
Q12007_1 <- Q12007 %>%
        select(!c(docket:idntigr))


#Q2 2007
Q22007 <- read.csv("2007Q2.csv")

Q22007$date <- "2Q2007"
Q22007_1 <- Q22007 %>%
        select(!c(docket:idntigr))


#Q3 2007
Q32007 <- read.csv("2007Q3.csv")

Q32007$date <- "3Q2007"
Q32007_1 <- Q32007 %>%
        select(!c(docket:idntigr))


#Q4 2007
Q42007 <- read.csv("2007Q4.csv")

Q42007$date <- "4Q2007"
Q42007_1 <- Q42007 %>%
        select(!c(docket:idntigr))

#Q1 2008
Q12008 <- read.csv("2008Q1.csv")

Q12008$date <- "1Q2008"
Q12008_1 <- Q12008 %>%
        select(!c(docket:idntigr))


#Q2 2008
Q22008 <- read.csv("2008Q2.csv")

Q22008$date <- "2Q2008"
Q22008_1 <- Q22008 %>%
        select(!c(docket:idntigr))


#Q3 2008
Q32008 <- read.csv("2008Q3.csv")

Q32008$date <- "3Q2008"
Q32008_1 <- Q32008 %>%
        select(!c(docket:idntigr))


#Q4 2008
Q42008 <- read.csv("2008Q4.csv")

Q42008$date <- "4Q2008"
Q42008_1 <- Q42008 %>%
        select(!c(docket:idntigr))


#Q1 2009
Q12009 <- read.csv("2009Q1.csv")

Q12009$date <- "1Q2009"
Q12009_1 <- Q12009 %>%
        select(!c(docket:idntigr))


#Q2 2009
Q22009 <- read.csv("2009Q2.csv")

Q22009$date <- "2Q2009"
Q22009_1 <- Q22009 %>%
        select(!c(docket:idntigr))


#Q3 2009
Q32009 <- read.csv("2009Q3.csv")



Q32009$date <- "3Q2009"
Q32009_1 <- Q32009 %>%
        select(!c(docket:idntigr))


#Q4 2009
Q42009 <- read.csv("2009Q4.csv")

Q42009$date <- "4Q2009"
Q42009_1 <- Q42009 %>%
        select(!c(docket:idntigr))


#Q1 2010
Q12010 <- read.csv("2010Q1.csv")

Q12010$date <- "1Q2010"
Q12010_1 <- Q12010 %>%
        select(!c(docket:idntigr))
#Q2 2010
Q22010 <- read.csv("2010Q2.csv")

Q22010$date <- "2Q2010"
Q22010_1 <- Q22010 %>%
        select(!c(docket:idntigr))

#Q3 2010
Q32010 <- read.csv("2010Q3.csv")

Q32010$date <- "3Q2010"
Q32010_1 <- Q32010 %>%
        select(!c(docket:idntigr))


#Q4 2010
Q42010 <- read.csv("2010Q4.csv")

Q42010$date <- "4Q2010"
Q42010_1 <- Q42010 %>%
        select(!c(docket:idntigr))


#Q1 2011
Q12011 <- read.csv("2011Q1.csv")

Q12011$date <- "1Q2011"
Q12011_1 <- Q12011 %>%
        select(!c(docket:idntigr))


#Q2 2011
Q22011 <- read.csv("2011Q2.csv")

Q22011$date <- "2Q2011"
Q22011_1 <- Q22011 %>%
        select(!c(docket:idntigr))


#Q3 2011
Q32011 <- read.csv("2011Q3.csv")

Q32011$date <- "3Q2011"
Q32011_1 <- Q32011 %>%
        select(!c(docket:idntigr))


#Q4 2011
Q42011 <- read.csv("2011Q4.csv")

Q42011$date <- "4Q2011"
Q42011_1 <- Q42011 %>%
        select(!c(docket:idntigr))


#Q1 2012
Q12012 <- read.csv("2012Q1.csv")

Q12012$date <- "1Q2012"
Q12012_1 <- Q12012 %>%
        select(!c(docket:idntigr))


#Q2 2012
Q22012 <- read.csv("2012Q2.csv")

Q22012$date <- "2Q2012"
Q22012_1 <- Q22012 %>%
        select(!c(docket:idntigr))


#Q3 2012
Q32012 <- read.csv("2012Q3.csv")

Q32012$date <- "3Q2012"
Q32012_1 <- Q32012 %>%
        select(!c(docket:idntigr))


#Q4 2012
Q42012 <- read.csv("2012Q4.csv")

Q42012$date <- "4Q2012"
Q42012_1 <- Q42012 %>%
        select(!c(docket:idntigr)) %>%
        transform(astempm = as.numeric(astempm))


#Q1 2013
Q12013 <- read.csv("2013Q1.csv")
head(Q12013)

Q12013$date <- "1Q2013"
Q12013_1 <- Q12013 %>%
        select(!c(docket:idntigr))


#Q2 2013
Q22013 <- read.csv("2013Q2.csv")

Q22013$date <- "2Q2013"
Q22013_1 <- Q22013 %>%
        select(!c(docket:idntigr))


#Q3 2013
Q32013 <- read.csv("2013Q3.csv")

Q32013$date <- "3Q2013"
Q32013_1 <- Q32013 %>%
        select(!c(docket:idntigr))


#Q4 2013
Q42013 <- read.csv("2013Q4.csv")

Q42013$date <- "4Q2013"
Q42013_1 <- Q42013 %>%
        select(!c(docket:idntigr))

#Q1 2014
Q12014 <- read.csv("2014Q1.csv")

Q12014$date <- "1Q2014"
Q12014_1 <- Q12014 %>%
        select(!c(docket:idntigr))

#Q2 2014 
Q22014 <- read.csv("2014Q2.csv")

Q22014$date <- "2Q2014"
Q22014_1 <- Q22014 %>%
        select(!c(docket:idntigr))

#Q3 2014
Q32014 <- read.csv("2014Q3.csv")

Q32014$date <- "3Q2014"
Q32014_1 <- Q32014 %>%
        select(!c(docket:idntigr))


#Q4 2014
Q42014 <- read.csv("2014Q4.csv")

Q42014$date <- "4Q2014"
Q42014_1 <- Q42014 %>%
        select(!c(docket:idntigr))


############################
#Joined Datasets

combined_quaterly_data <- bind_rows(Q12006_1, Q22006_1, Q32006_1, Q42006_1, Q12007_1, Q22007_1, Q32007_1, Q42007_1, Q12008_1, Q22008_1, Q32008_1, Q42008_1, Q12009_1, Q22009_1, Q32009_1, Q42009_1, Q12010_1, Q22010_1, Q32010_1, Q42010_1, Q12011_1, Q22011_1, Q32011_1, Q42011_1, Q12012_1, Q22012_1, Q32012_1, Q42012_1, Q12013_1, Q22013_1, Q32013_1, Q42013_1, Q12014_1, Q22014_1, Q32014_1, Q42014_1)


#Q12000_1, Q22000_1, Q32000_1, Q42000_1, Q12001_1, Q22001_1, Q32001_1, Q42001_1, Q12002_1, Q22002_1, Q32002_1, Q42002_1, Q12003_1, Q22003_1, Q32003_1, Q42003_1, Q12004_1, Q22004_1, Q32004_1, Q42004_1, Q12005_1, Q22005_1, Q32005_1, Q42005_1, Q12006_1, Q22006_1, Q32006_1, Q42006_1, Q12007_1, Q22007_1, Q32007_1, Q42007_1,
```


Data Clean Up
```{r}

# Using Cert to assign a 0 if healthy and a 1 if insolvent or needing assistance
combined_quaterly_data$solvency <- ifelse(combined_quaterly_data$cert %in% bank_failures_2$Cert., 1,0)

#Test 
combined_quaterly_data%>%
        filter(cert == 57431) %>%
        head()


# rename date column for easier data aggregation

combined_quaterly_data <- combined_quaterly_data %>%
        rename(DATE = "date")


# Examine NA's and deciding what columns to remove 

combined_quaterly_data %>%
        summarise_each(funs(100*mean(is.na(.))))

combined_quaterly_data %>%
        filter(solvency == 1) %>%
        summarise_each(funs(100*mean(is.na(.))))

combined_quaterly_data %>%
        filter(solvency == 0) %>%
        summarise_each(funs(100*mean(is.na(.))))

combined_quaterly_data_2 <- combined_quaterly_data %>%
        select(!c(rbct1cer, cblrind, idt1cer, idt1rwajr, iderncvr, lnresncr, rbc1rwaj, ernastr, elnantr, elnatry))


combined_quaterly_data_2.1 <- combined_quaterly_data_2 %>%
        group_by(cert) %>%
        na.omit()

combined_quaterly_data_2.1$solvency <- as.factor(combined_quaterly_data_2.1$solvency)

class(combined_quaterly_data_2.1$solvency)
unique(combined_quaterly_data_2$cert)
unique(combined_quaterly_data_2.1$cert)
head(combined_quaterly_data_2.1)

#log transformation 
#combined_quaterly_data_2.1[,26:29] <- log(combined_quaterly_data_2.1[,26:29])
#head(combined_quaterly_data_2.1)
```



# Adding Macroeconomic Indicators
### Deal with extra macroeconomic indicators later
```{r}

# Real GDP % change indicator
rgdp <- read.csv("Real GDP.csv")
rgdp$DATE <- as.Date(rgdp$DATE, origin = "1899-12-30") 

#Clean up code of date for one line
rgdp <- rgdp %>%
        filter(DATE <= "2014-12-01") %>%
        filter(DATE > "2005-12-01")

tail(rgdp)

quaters <- unique(combined_quaterly_data_2.1$DATE)
quaters

rgdp$DATE <- quaters
unique(combined_quaterly_data_2.1$DATE)

head(rgdp)

combined_quaterly_data_2.1 <- left_join(combined_quaterly_data_2.1, rgdp, by = "DATE")
combined_quaterly_data_2.1 <-  combined_quaterly_data_2.1 %>%
        rename("GDP" = GDPC1_PCH)
        
head(combined_quaterly_data_2.1)
        
        
        
# CPI index indicator

cpi <- read.csv("CPI.csv")
cpi$DATE <- as.Date(cpi$DATE, origin = "1899-12-30") 
cpi <- cpi %>%
        filter(DATE <= "2014-12-01") %>%
        filter(DATE > "2005-12-01")
cpi$DATE <- quaters
        
combined_quaterly_data_2.1 <- left_join(combined_quaterly_data_2.1, cpi, by = "DATE")        
combined_quaterly_data_2.1 <-  combined_quaterly_data_2.1 %>%
        rename("CPI" = CPALTT01USM657N)        


# Effective Federal funds rate Quatertly average
eff <- read.csv("FEDFUNDS (3).csv")
eff$DATE <- as.Date(eff$DATE, origin = "1899-12-30") 
eff <- eff %>%
        filter(DATE <= "2014-12-01") %>%
        filter(DATE > "2005-12-01")
eff$DATE <- quaters

combined_quaterly_data_2.1 <- left_join(combined_quaterly_data_2.1, eff, by = "DATE") 

#combined_quaterly_data_2.1$scaled_asset5 <- scale(combined_quaterly_data_2.1$asset5) 
#combined_quaterly_data_2.1$scaled_ernast5 <- scale(combined_quaterly_data_2.1$ernast5) 
#combined_quaterly_data_2.1$scaled_lnlsgr5 <- scale(combined_quaterly_data_2.1$lnlsgr5) 
#combined_quaterly_data_2.1$scaled_eq5 <- scale(combined_quaterly_data_2.1$eq5) 

#combined_quaterly_data_2.1 <- combined_quaterly_data_2.1 %>%
#        select(!c(asset5, ernast5, lnlsgr5, eq5))

head(combined_quaterly_data_2.1)
```

Marcoeconomic indcators
Asset prices (Stock and house prices)
business cycle indactors (real GDP growth, cpi inflation)
private sector credit growth
- country-level banking-sector indicators (non-core liabilities,  high debt-to-equity ratio,  total assets to GDP, debt securities to liabilities)


# Quaterly Ratio variable names in combined_quaterly_data_2.1

- intincy  = Yeild on earning assets  (Total Interest income/Total Average Earnings assets)
- intexpy  = Cost of funding earning assets 
- nimy     = Net interest margin ((Non-interest income - non-interest expense)/Total earning assets)
- noniiay  = Noninterest income to average assets (Non-interest income/ average assets)
- nonixay  = Noninterest expense to average assets (Non-interest expense/ average assets)
- noijy    = Net operating income to assets  (Net-opertating income/ assets)
- roa      = Return on assets (Net Income/ Total Average Assets)
- roaptx   = Pretax return on assets (Pre-tax earnings/ Total Assets)
- roe      = Return on equity (Net Income/ Shareholders Equity)
- roeinjr  = Retained earnings to average equity (YTD only) (Retained Earnings/ Average Equity)
- ntlnlsr  = Net Charge-offs to loans (Net Charge offs / average total loans 
- eeffr    = Efficency Ration ( non-interest expenses/ revenue)
- astempm  = Assets per employee (Total assets/ # of employees)
- iddivnir = Cash dividends to net income (ytd only) (Total cash dividends/ net income)
- lnatrest = Loan lease allowance to loans ( loan lease allowance / total loans)
- nperfv   = Noncurrent assets plus other real estate (Noncurrent assets / Total Assets)
- nclnlsr  = Non-current loans to loans (Non-current loans/ Total LOans)
- lnlsntv  = Net loans and leases to total assets (Net loans and leases/ total assets)
- lnlsdepr = net loans and leases to deposits (Net loans and leases/ Deposits)
- idlncoor = net loans and leases to core deposits (Net loans and leases / Core deposits)
- depdastr = total domestic deposits to total assets ( Total domestic deposits / total assets)
- eqv      = Equity capital to assets (Total equity capital /  total assets)
- rbc1aaj  = Leverage (core capital) ratio  (Tier 1 capital / (average assets - ineligible intangibles))
- rbcrwaj  = Total risk based capital ration ()
- asset5   = Average total assets 
- ernast5  = Average Earning Assets 
- lnlsgr5  = Average Total Loans



#Lag variables function
#Make sure when adding lags for a actual copy instead of test run we use all data so we do not end up with NA'

```{r}
#Function creating 8 lags per variable
lags <- function (data, y) {


data %>%
        group_by(cert) %>%
        mutate( "1" = lag({{y}}, n = 1),
                "2" = lag({{y}}, n = 2), 
                "3" = lag({{y}}, n = 3),
                "4" = lag({{y}}, n = 4),
                "5" = lag({{y}}, n = 5), 
                "6" = lag({{y}}, n = 6), 
                "7" = lag({{y}}, n = 7), 
                "8" = lag({{y}}, n = 8))
}

#Original
#lags <- function (data, y) {


#data %>%
#        group_by(cert) %>%
#        mutate( a = lag({{y}}, n = 1)) 
#}

#combined_quaterly_data_L1 <- lags(combined_quaterly_data_2.1, intincy)
# Lags for iniincy
colnames(combined_quaterly_data_2.1)
```

# Variable lags
```{r}

#intincy lag
combined_quaterly_data_L1 <- lags(combined_quaterly_data_2.1, intincy)
colnames(combined_quaterly_data_L1)[35:42] <- paste("intincy", colnames(combined_quaterly_data_L1[,c(35:42)]), sep = "_")

# intexpy lag
combined_quaterly_data_L2 <- lags(combined_quaterly_data_L1, intexpy)
colnames(combined_quaterly_data_L2)[43:50] <- paste("intexpy", colnames(combined_quaterly_data_L2[,c(43:50)]), sep = "_")

# nimy lag
combined_quaterly_data_L3 <- lags(combined_quaterly_data_L2, nimy)
colnames(combined_quaterly_data_L3)[51:58] <- paste("nimy", colnames(combined_quaterly_data_L3[,c(51:58)]), sep = "_")

# noniiay lag
combined_quaterly_data_L4 <- lags(combined_quaterly_data_L3, noniiay)
colnames(combined_quaterly_data_L4)[59:66] <- paste("noniiay", colnames(combined_quaterly_data_L4[,c(59:66)]), sep = "_")

# nonixay lag
combined_quaterly_data_L5 <- lags(combined_quaterly_data_L4, nonixay)
colnames(combined_quaterly_data_L5)[67:74] <- paste("nonixay", colnames(combined_quaterly_data_L5[,c(67:74)]), sep = "_")

# noijy lag
combined_quaterly_data_L6 <- lags(combined_quaterly_data_L5, noijy)
colnames(combined_quaterly_data_L6)[75:82] <- paste("noijy", colnames(combined_quaterly_data_L6[,c(75:82)]), sep = "_")

# roa lag
combined_quaterly_data_L7 <- lags(combined_quaterly_data_L6, roa)
colnames(combined_quaterly_data_L7)[83:90] <- paste("roa", colnames(combined_quaterly_data_L7[,c(83:90)]), sep = "_")

# roaptx lag
combined_quaterly_data_L8 <- lags(combined_quaterly_data_L7, roaptx)
colnames(combined_quaterly_data_L8)[91:98] <- paste("roaptx", colnames(combined_quaterly_data_L8[,c(91:98)]), sep = "_")

# roe lag
combined_quaterly_data_L9 <- lags(combined_quaterly_data_L8, roe)
colnames(combined_quaterly_data_L9)[99:106] <- paste("roe", colnames(combined_quaterly_data_L9[,c(99:106)]), sep = "_")

# roeinjr lag
combined_quaterly_data_L10 <- lags(combined_quaterly_data_L9, roeinjr)
colnames(combined_quaterly_data_L10)[107:114] <- paste("roeinjr", colnames(combined_quaterly_data_L10[,c(107:114)]), sep = "_")

# ntlnlsr lag
combined_quaterly_data_L11 <- lags(combined_quaterly_data_L10, ntlnlsr)
colnames(combined_quaterly_data_L11)[115:122] <- paste("ntlnlsr", colnames(combined_quaterly_data_L11[,c(115:122)]), sep = "_")

# eeffr lag
combined_quaterly_data_L12 <- lags(combined_quaterly_data_L11, eeffr)
colnames(combined_quaterly_data_L12)[123:130] <- paste("eeffr", colnames(combined_quaterly_data_L12[,c(123:130)]), sep = "_")

# astempm lag
combined_quaterly_data_L13 <- lags(combined_quaterly_data_L12, astempm)
colnames(combined_quaterly_data_L13)[131:138] <- paste("astempm", colnames(combined_quaterly_data_L13[,c(131:138)]), sep = "_")

# iddivnir lag
combined_quaterly_data_L14 <- lags(combined_quaterly_data_L13, iddivnir )
colnames(combined_quaterly_data_L14)[139:146] <- paste("iddivnir", colnames(combined_quaterly_data_L14[,c(139:146)]), sep = "_")

# lnatresr lag
combined_quaterly_data_L15 <- lags(combined_quaterly_data_L14, lnatresr )
colnames(combined_quaterly_data_L15)[147:154] <- paste("lnatresr", colnames(combined_quaterly_data_L15[,c(147:154)]), sep = "_")

# nperfv lag
combined_quaterly_data_L16 <- lags(combined_quaterly_data_L15, nperfv )
colnames(combined_quaterly_data_L16)[155:162] <- paste("nperfv", colnames(combined_quaterly_data_L16[,c(155:162)]), sep = "_")

# nclnlsr lag
combined_quaterly_data_L17 <- lags(combined_quaterly_data_L16, nclnlsr )
colnames(combined_quaterly_data_L17)[163:170] <- paste("nclnlsr", colnames(combined_quaterly_data_L17[,c(163:170)]), sep = "_")

# lnlsntv lag
combined_quaterly_data_L18 <- lags(combined_quaterly_data_L17, lnlsntv )
colnames(combined_quaterly_data_L18)[171:178] <- paste("lnlsntv", colnames(combined_quaterly_data_L18[,c(171:178)]), sep = "_")

# lnlsdepr lag
combined_quaterly_data_L19 <- lags(combined_quaterly_data_L18, lnlsdepr )
colnames(combined_quaterly_data_L19)[179:186] <- paste("lnlsdepr", colnames(combined_quaterly_data_L19[,c(179:186)]), sep = "_")

# idlncorr lag
combined_quaterly_data_L20 <- lags(combined_quaterly_data_L19, idlncorr )
colnames(combined_quaterly_data_L20)[187:194] <- paste("idlncorr", colnames(combined_quaterly_data_L20[,c(187:194)]), sep = "_")

# depdastr lag
combined_quaterly_data_L21 <- lags(combined_quaterly_data_L20, depdastr )
colnames(combined_quaterly_data_L21)[195:202] <- paste("depdastr", colnames(combined_quaterly_data_L21[,c(195:202)]), sep = "_")

# eqv lag
combined_quaterly_data_L22 <- lags(combined_quaterly_data_L21, eqv )
colnames(combined_quaterly_data_L22)[203:210] <- paste("eqv", colnames(combined_quaterly_data_L22[,c(203:210)]), sep = "_")

# rbc1aaj lag
combined_quaterly_data_L23 <- lags(combined_quaterly_data_L22, rbc1aaj )
colnames(combined_quaterly_data_L23)[211:218] <- paste("rbc1aaj", colnames(combined_quaterly_data_L23[,c(211:218)]), sep = "_")

# rbcrwaj lag
combined_quaterly_data_L24 <- lags(combined_quaterly_data_L23, rbcrwaj )
colnames(combined_quaterly_data_L24)[219:226] <- paste("rbcrwaj", colnames(combined_quaterly_data_L24[,c(219:226)]), sep = "_")

# asset5 lag
combined_quaterly_data_L25 <- lags(combined_quaterly_data_L24, asset5 )
colnames(combined_quaterly_data_L25)[227:234] <- paste("scaled_asset5", colnames(combined_quaterly_data_L25[,c(227:234)]), sep = "_")

# ernast5 lag
combined_quaterly_data_L26 <- lags(combined_quaterly_data_L25, ernast5 )
colnames(combined_quaterly_data_L26)[235:242] <- paste("scaled_ernast5", colnames(combined_quaterly_data_L26[,c(235:242)]), sep = "_")

# eq5 lag
combined_quaterly_data_L27 <- lags(combined_quaterly_data_L26, eq5 )
colnames(combined_quaterly_data_L27)[243:250] <- paste("scaled_eq5", colnames(combined_quaterly_data_L27[,c(243:250)]), sep = "_")

# lnlsgr5 lag
combined_quaterly_data_L28 <- lags(combined_quaterly_data_L27, lnlsgr5 )
colnames(combined_quaterly_data_L28)[251:258] <- paste("scaled_lnlsgr5", colnames(combined_quaterly_data_L28[,c(251:258)]), sep = "_")

# GDP% lag
combined_quaterly_data_L29 <- lags(combined_quaterly_data_L28, GDP )
colnames(combined_quaterly_data_L29)[259:266] <- paste("GDP", colnames(combined_quaterly_data_L29[,c(259:266)]), sep = "_")

# CPI lag 
combined_quaterly_data_L30 <- lags(combined_quaterly_data_L29, CPI )
colnames(combined_quaterly_data_L30)[267:274] <- paste("CPI", colnames(combined_quaterly_data_L30[,c(267:274)]), sep = "_")

# FEDFUNDS lag
combined_quaterly_data_L31 <- lags(combined_quaterly_data_L30, FEDFUNDS )
colnames(combined_quaterly_data_L31)[275:282] <- paste("FEDFUNDS", colnames(combined_quaterly_data_L31[,c(275:282)]), sep = "_")

combined_quaterly_data_FL <- combined_quaterly_data_L31 %>%
       group_by(cert) %>%
       na.omit()



combined_quaterly_data_FL %>%
        filter(cert == 57899)
```




# Setting up split between out of time validation and in time train/test
```{r}
#combined_quaterly_data_FL <- combined_quaterly_data_FL %>%
#        select(!DATE)
#head(combined_quaterly_data_FL)

#Out of time validation set
outoftime <- combined_quaterly_data_FL[grepl(c("2014|2013"), combined_quaterly_data_FL$DATE),]
outoftime <- outoftime %>%
        ungroup(cert) %>%
        select(!c(DATE, cert))


head(outoftime)
#outoftime <- combined_quaterly_data_2.1[grepl(c("2014|2013"), combined_quaterly_data_2.1$DATE),]
# Train/Test set
TT <- combined_quaterly_data_FL[!grepl(c("2014|2013"), combined_quaterly_data_FL$DATE),]
TT <- TT %>%
        ungroup(cert) %>%
        select(!c(DATE, cert))
#TT <- combined_quaterly_data_2.1[!grepl(c("2014|2013"), combined_quaterly_data_2.1$DATE),]

``` 


#undersampling techniques. Train test split
```{R}

train.index <- createDataPartition(TT$solvency, p = .8, list = FALSE)

step_train <- TT[train.index,]
step_test <- TT[-train.index,]

#Figure out clean way to do this
#table(step_train$solvency)
#3090/118576

#3090*10
#30900/118576

#15655
#15655/118576 = .132025
# under sampled majority class so that minority class is 10%
short_0 <- step_train %>%
        filter(solvency == 0) %>%
        sample_frac(.2605924)

short_1 <- step_train %>%
        filter(solvency == 1)

short_train_10 <- rbind(short_0, short_1)
table(short_train_10$solvency)


#
```


# Test cases




#k fold validation
```{r}
set.seed(111)
start.time <- proc.time()


lr_recipe <-
        recipe(solvency ~., data = short_train_10) %>%
        prep

rs <- vfold_cv(short_train_10, repeats = 10, strata = solvency)
tune_spec <- logistic_reg(penalty = tune(), mixture = tune()) %>%
        set_engine("glmnet")
wf <- workflow() %>%
        add_recipe(lr_recipe) %>%
        remove_formula() %>%
        add_formula(solvency ~.)
my_grid <- grid_regular(penalty(), mixture())
results <- tune_grid(wf %>%
                             add_model(tune_spec), resamples = rs, grid = my_grid, metrics = metric_set(roc_auc))
most_accurate <- results %>%
        select_best("roc_auc")
final <- finalize_workflow(wf %>%
                                   add_model(tune_spec), most_accurate)
glmnet_fit <- fit(final, data = short_train_10)
baked <- bake(lr_recipe, new_data = step_test)
bind_cols(solvency = step_test$solvency, 
          predict(glmnet_fit, new_data = step_test)) %>%
        conf_mat(truth = solvency, estimate = .pred_class)


stop.time <- proc.time()
run.time <- stop.time - start.time
print(run.time)
?grid_regular
```


# Bootstrap
```{r}

# check stratufued bootstrapping
#cl <- makePSOCKcluster(4)
#registerDoParallel(cl)

start.time <- proc.time()



lr_recipe <-
        recipe(solvency ~., data = short_train_10) %>%
        prep

rs <- bootstraps(short_train_10, times = 10, strata = solvency, maxit = 500000)
tune_spec <- logistic_reg(penalty = tune(), mixture = tune()) %>%
        set_engine("glmnet")
wf <- workflow() %>%
        add_recipe(lr_recipe) %>%
        remove_formula() %>%
        add_formula(solvency ~.)
my_grid <- grid_regular(penalty(), mixture())
results <- tune_grid(wf %>%
                             add_model(tune_spec), resamples = rs, grid = my_grid,  control = control_grid(save_pred = TRUE), metrics = metric_set(roc_auc))
most_accurate <- results %>%
        select_best("roc_auc")
final <- finalize_workflow(wf %>%
                                   add_model(tune_spec), most_accurate)
glmnet_fit <- fit(final, data = short_train_10)
baked <- bake(lr_recipe, new_data = step_test)
bind_cols(solvency = step_test$solvency, 
          predict(glmnet_fit, new_data = step_test)) %>%
        conf_mat(truth = solvency, estimate = .pred_class)


stop.time <- proc.time()
run.time <- stop.time - start.time
print(run.time)

#stopCluster(cl)



```



# smote Undersample so it is even
```{r}
start.time <- proc.time()

lr_recipe <-
        recipe(solvency ~., data = step_train) %>% 
        step_smote(solvency) %>%
        prep

rs <- vfold_cv(step_train, repeats = 10, strata = solvency)
tune_spec <- logistic_reg(penalty = tune(), mixture = tune()) %>%
        set_engine("glmnet") 
wf <- workflow() %>%
        add_recipe(lr_recipe) %>%
        remove_formula() %>%
        add_formula(solvency ~.)
my_grid <- grid_regular(penalty(), mixture())
results <- tune_grid(wf %>%
                             add_model(tune_spec), resamples = rs, grid = my_grid,  control = control_grid(save_pred = TRUE), metrics = metric_set(roc_auc))
most_accurate <- results %>% 
        select_best("roc_auc")
final <- finalize_workflow(wf %>%
                                   add_model(tune_spec), most_accurate)
glmnet_fit <- fit(final, data = step_train)
baked <- bake(lr_recipe, new_data = step_test)
bind_cols(solvency = step_test$solvency, 
          predict(glmnet_fit, new_data = step_test)) %>%
        conf_mat(truth = solvency, estimate = .pred_class)


stop.time <- proc.time()
run.time <- stop.time - start.time
print(run.time)


predicted_1 <- predicted %>%
        select(".pred_1", "solvency")
dim(predicted_1)
roc_auc(predicted_1, ".pred_1")
predicted$.
?roc_auc

class(predicted)
lr_recipe
# Get the predicted values for each observation
predicted <- step_test %>%   
        bind_cols(predict( glmnet_fit, step_test)) %>%
        bind_cols(predict(glmnet_fit, step_test, type = "prob"))
predicted[, 283]

# ROC_AUC curve
predicted %>%
        roc_auc(solvency, .pred_1)

roc_data <- tibble("auc"= roc_auc(predicted, solvency, .pred_1) %>%
                           select(.estimate) %>%
                           unnest(everything()) %>%
                           pivot_longer(everything(), names_to = "metric", values_to = "values") %>%
                           mutate(model = "pred_only")
                   
head(roc_data)
predicted %>%
        roc_curve(solvency, .pred_1) %>%
        ggplot(aes(x = 1 - specificity, y = sensitivity)) +
                       geom_path() +
                       geom_abline(lty = 3) +
                       coord_equal() +
                       theme_classic()
  
               
               
               
predicted %>%
        roc_curve(solvency, .pred_1) %>%
        autoplot()



# Train data
predicted <- step_test %>%
        bind_cols(predict( final, step_train)) %>%
        bind_cols(predict(final, step_train, type = "prob"))



predicted
predicted[, 280:283]
?predict                            
```

```{r}





```



#PCA
```{r}
combined_quaterly_data_T <- combined_quaterly_data_FL %>%
        ungroup(cert) %>%
        select(!c(DATE)) 
combined_quaterly_data_T$solvency <- as.numeric(combined_quaterly_data_T$solvency)


cl <- makePSOCKcluster(4)
registerDoParallel(cl)
start.time <- proc.time()

robust <- pcaPP::PCAproj(combined_quaterly_data_T, scale = "sd", center = "mean")
factoextra::fviz_pca_biplot(robust) + ggtitle("Robust PCA")
fviz_eig(robust)

stop.time <- proc.time() 
run.time <- stop.time - start.time
print(run.time)
stopCluster(cl)

# Not roboust PCA
regular <- prcomp(combined_quaterly_data_T, scale. = TRUE, center = TRUE)
factoextra::fviz_pca_biplot(regular) + ggtitle("Not robust PCA")

detectCores()
```









# Random Forest
```{r}
rf_recipe <-
        recipe(solvency ~., data = short_train_10) %>%
        prep

rs <- bootstraps(short_train_10, times = 10, maxit = 500000)
tune_spec <- rand_forest(trees = tune(), mtry = tune(), min_n = tune(), mode = "classification") %>%
        set_engine("ranger")
wf <- workflow() %>%
        add_recipe(rf_recipe) %>%
        remove_formula() %>%
        add_formula(solvency ~.)
my_grid <- grid_regular(trees(), mtry(), min_n())
results <- tune_grid(wf %>%
                             add_model(tune_spec), resamples = rs, grid = my_grid, metrics = metric_set(roc_auc))
most_accurate <- results %>%
        select_best("roc_auc")
final <- finalize_workflow(wf %>%
                                   add_model(tune_spec), most_accurate)
glmnet_fit <- fit(final, data = short_train_10)
baked <- bake(rf_recipe, new_data = step_test)
bind_cols(solvency = step_test$solvency, 
          predict(glmnet_fit, new_data = step_test)) %>%
        conf_mat(truth = solvency, estimate = .pred_class)

```




# Extra code
# Correlation
```{r}
# correlation tests
test <- combined_quaterly_data_2.1 %>%
        select(!c(DATE))

test$solvency <- as.numeric(combined_quaterly_data_2.1$solvency)

corr.d <- cor(test)
corr.d[ lower.tri( corr.d, diag = TRUE ) ] <- NA
corrplot( corr.d, type = "upper", diag = FALSE )


# sort pairs of correlated variables
m <- melt( corr.d )
m <- m[order(- abs(m$value)), ]
# get rid of NAs
m <- na.omit(m)
# view the highest correlated: rho > 0.5
(m[ which( m$value > 0.5 ), ])


head(combined_quaterly_data_2.1)

```


